{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'PassengerId', u'Survived', u'Pclass', u'Name', u'Sex', u'Age',\n",
      "       u'SibSp', u'Parch', u'Ticket', u'Fare', u'Cabin', u'Embarked'],\n",
      "      dtype='object')\n",
      "Index([u'PassengerId', u'Pclass', u'Name', u'Sex', u'Age', u'SibSp', u'Parch',\n",
      "       u'Ticket', u'Fare', u'Cabin', u'Embarked'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('./titanic.csv')\n",
    "tds = pd.read_csv('./test.csv')\n",
    "print ds.columns\n",
    "print tds.columns\n",
    "ds.head(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891,)\n",
      "(418,)\n",
      "[ 0.  1.  1.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  0.  0.\n",
      "  1.  1.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.\n",
      "  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.\n",
      "  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  1.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  1.  0.  0.\n",
      "  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.\n",
      "  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.\n",
      "  0.  1.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.\n",
      "  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.\n",
      "  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  1.  1.  0.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  0.\n",
      "  1.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.  1.\n",
      "  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.\n",
      "  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.\n",
      "  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  1.  1.  1.  0.\n",
      "  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  0.\n",
      "  1.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.\n",
      "  0.  1.  1.  1.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.\n",
      "  1.  0.  0.  1.  1.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.\n",
      "  1.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  0.\n",
      "  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  0.  1.\n",
      "  1.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.\n",
      "  1.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.\n",
      "  1.  1.  1.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.\n",
      "  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.\n",
      "  1.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  0.\n",
      "  0.  1.  0.  1.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.\n",
      "  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.\n",
      "  1.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.\n",
      "  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.\n",
      "  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.\n",
      "  1.  0.  0.  1.  0.  1.  1.  0.  0.]\n",
      "[ 0.  1.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.\n",
      "  1.  1.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.\n",
      "  1.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.  1.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  0.\n",
      "  1.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.\n",
      "  1.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.\n",
      "  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.\n",
      "  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.\n",
      "  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.\n",
      "  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.\n",
      "  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  0.  1.\n",
      "  0.  1.  1.  0.  1.  1.  0.  1.  1.  0.  0.  1.  0.  0.  1.  1.  1.  0.\n",
      "  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.\n",
      "  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.\n",
      "  1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "mean_Age = ds['Age'].mean()\n",
    "ds['Age'] = ds['Age'].fillna(int(mean_Age))\n",
    "\n",
    "test_mean_Age = tds['Age'].mean()\n",
    "tds['Age'] = tds['Age'].fillna(int(test_mean_Age))\n",
    "\n",
    "sex_mapping = {\n",
    "    'male': 0,\n",
    "    'female': 1\n",
    "}\n",
    "\n",
    "sex = ds['Sex'].values\n",
    "Sex = tds['Sex'].values\n",
    "print sex.shape\n",
    "print Sex.shape\n",
    "quant_sex = np.zeros(sex.shape)\n",
    "test_quant_sex = np.zeros(Sex.shape)\n",
    "\n",
    "for ix in range(quant_sex.shape[0]):\n",
    "    quant_sex[ix] = sex_mapping[sex[ix]]\n",
    "\n",
    "for ix in range(test_quant_sex.shape[0]):\n",
    "    test_quant_sex[ix] = sex_mapping[Sex[ix]]\n",
    "#print quant_sex\n",
    "#print test_quant_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 22.     3.     1.     0.     7.25   0.     0.  ]\n",
      "[ 34.5      3.       0.       0.       7.8292   0.    ]\n"
     ]
    }
   ],
   "source": [
    "data = np.asarray([ds['Age'], ds['Pclass'], ds['SibSp'],\n",
    "        ds['Parch'], ds['Fare'], quant_sex,\n",
    "        ds['Survived']]).astype(\"float\").T\n",
    "Y = ds['Survived'].values\n",
    "cols = ['Age', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Sex', 'Survived']\n",
    "print data[0]\n",
    "# ds.head(n=1)\n",
    "\n",
    "test_data = np.array([tds['Age'], tds['Pclass'], tds['SibSp'],\n",
    "        tds['Parch'], tds['Fare'], test_quant_sex]).astype(\"float\").T\n",
    "cols = ['Age', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Sex']\n",
    "print test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_split(dataset, col_id, value):\n",
    "    data_right = []\n",
    "    data_left = []\n",
    "    \n",
    "    # send greater values to right and smaller or equal to left\n",
    "    for ix in range(dataset.shape[0]):\n",
    "        if dataset[ix, col_id] <= value:\n",
    "            data_left.append(dataset[ix, :])\n",
    "        else:\n",
    "            data_right.append(dataset[ix, :])\n",
    "    return np.asarray(data_right), np.asarray(data_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(dataset, col=-1):\n",
    "    if dataset.shape[0] == 0:\n",
    "        return 0\n",
    "    p = dataset[:, col].mean()\n",
    "    if p == 1 or p == 0:\n",
    "        return 0.0\n",
    "    ent = (-1.0 * p * np.log2(p)) + (-1.0 * (1.0 - p) * np.log2(1.0 - p))\n",
    "    return ent\n",
    "    \n",
    "def information_gain(parent_set, child_1, child_2):\n",
    "    # print parent_set.shape, child_1.shape, child_2.shape\n",
    "    ent_p = entropy(parent_set)\n",
    "    ent_c1 = entropy(child_1)\n",
    "    ent_c2 = entropy(child_2)\n",
    "    \n",
    "    f = float(child_1.shape[0])/parent_set.shape[0]\n",
    "    Ig = ent_p - (f*ent_c1 + (1-f)*ent_c2)\n",
    "    return Ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INF = 100000\n",
    "class DT:\n",
    "    def __init__(self, depth=0, max_depth=10):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.col_id = None\n",
    "        self.value = None\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.n_survival = None\n",
    "        self.n_death = None\n",
    "    \n",
    "    def get_best_gain(self, dataset):\n",
    "        \n",
    "        n_cols = 6 # number of columns in data\n",
    "        all_gains = []\n",
    "        \n",
    "        self.n_survival = dataset[:, -1].sum()\n",
    "        self.n_death = dataset.shape[0] - self.n_survival\n",
    "        \n",
    "        for cx in range(n_cols):\n",
    "            mean_val_cx = dataset[:, cx].mean()\n",
    "            right, left = data_split(dataset, cx, mean_val_cx)\n",
    "            \n",
    "            total_gain = information_gain(dataset, right, left)\n",
    "            all_gains.append(total_gain)\n",
    "            \n",
    "        self.col_id = np.asarray(all_gains).argmax()\n",
    "        self.value = dataset[:, self.col_id].mean()\n",
    "        \n",
    "        data_right, data_left = data_split(dataset, self.col_id, self.value)\n",
    "        \n",
    "        if data_left.shape[0] > 0 and self.depth < self.max_depth:\n",
    "            self.left = DT(depth=self.depth+1, max_depth=self.max_depth)\n",
    "            self.left.get_best_gain(data_left)\n",
    "            \n",
    "        if data_right.shape[0] > 0 and self.depth < self.max_depth:\n",
    "            self.right = DT(depth=self.depth+1, max_depth=self.max_depth)\n",
    "            self.right.get_best_gain(data_right)\n",
    "        return\n",
    "    \n",
    "    def predict(self, example):\n",
    "        exp_val = example[self.col_id]\n",
    "        # print self.n_survival, self.n_death, self.depth\n",
    "        # print self.col_id, exp_val, self.value, '-------------'\n",
    "        if exp_val <= self.value:\n",
    "            if not self.left == None:\n",
    "                # print 'going left'\n",
    "                return self.left.predict(example)\n",
    "            else:\n",
    "                # print 'end left'\n",
    "                return self.decide()\n",
    "        else:\n",
    "            if not self.right == None:\n",
    "                # print 'going right'\n",
    "                return self.right.predict(example)\n",
    "            else:\n",
    "                # print 'end right'\n",
    "                return self.decide()\n",
    "    \n",
    "    def decide(self):\n",
    "        # print self.depth\n",
    "        if self.n_survival >= self.n_death:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418,)\n",
      "(418,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data[:, :]\n",
    "y_test = test_data[:, :]\n",
    "\n",
    "y_pred = np.zeros(y_test.shape[0])\n",
    "print y_pred.shape\n",
    "dt = DT(max_depth=6)\n",
    "dt.get_best_gain(X_train)\n",
    "\n",
    "for rx in range(y_test.shape[0]):\n",
    "    y_pred[rx] = dt.predict(y_test[rx, :])\n",
    "\n",
    "y_pred = y_pred.astype(\"int\", copy= False)\n",
    "    \n",
    "print y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         1\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         0\n",
      "5            897         0\n",
      "6            898         1\n",
      "7            899         0\n",
      "8            900         1\n",
      "9            901         0\n",
      "10           902         0\n",
      "11           903         0\n",
      "12           904         1\n",
      "13           905         0\n",
      "14           906         1\n",
      "15           907         1\n",
      "16           908         0\n",
      "17           909         0\n",
      "18           910         1\n",
      "19           911         1\n",
      "20           912         0\n",
      "21           913         1\n",
      "22           914         1\n",
      "23           915         1\n",
      "24           916         1\n",
      "25           917         0\n",
      "26           918         1\n",
      "27           919         0\n",
      "28           920         0\n",
      "29           921         0\n",
      "..           ...       ...\n",
      "388         1280         0\n",
      "389         1281         0\n",
      "390         1282         1\n",
      "391         1283         1\n",
      "392         1284         1\n",
      "393         1285         0\n",
      "394         1286         0\n",
      "395         1287         1\n",
      "396         1288         0\n",
      "397         1289         1\n",
      "398         1290         0\n",
      "399         1291         0\n",
      "400         1292         1\n",
      "401         1293         0\n",
      "402         1294         1\n",
      "403         1295         1\n",
      "404         1296         0\n",
      "405         1297         0\n",
      "406         1298         0\n",
      "407         1299         0\n",
      "408         1300         1\n",
      "409         1301         0\n",
      "410         1302         1\n",
      "411         1303         1\n",
      "412         1304         1\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#d = np.zeros((y_pred, ))\n",
    "d= pd.DataFrame({'PassengerId': tds['PassengerId'] , 'Survived': y_pred})\n",
    "print d\n",
    "d.to_csv('test_results.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
